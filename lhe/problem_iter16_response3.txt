```python
def heuristics_v2(distance_matrix, demands):
    n = distance_matrix.shape[0]
    
    # Initialize attentional bias matrix
    attentional_bias = torch.zeros_like(distance_matrix)
    
    # Calculate the maximum possible demand that can be accommodated
    max_demand = 1.0 - demands[0]
    
    # Normalize demands by dividing by the maximum possible demand
    normalized_demands = demands / max_demand

    # Calculate the mean distance
    mean_distance = torch.mean(distance_matrix)
    
    # Calculate the attentional bias matrix using efficient vectorized implementation
    attentional_bias = distance_matrix / mean_distance / normalized_demands.view(-1, 1)
    
    # Set zero values for NaN and Inf
    attentional_bias[torch.isnan(attentional_bias)] = 0
    attentional_bias[torch.isinf(attentional_bias)] = 0

    return attentional_bias
```
In this improved version, unnecessary calculations and use of precomputed values have been avoided. The demands are normalized by dividing by the maximum possible demand, and the mean distance is calculated as a more meaningful metric for bias calculation. The vectorized implementation remains efficient.
