```python
def heuristics_v2(distance_matrix: torch.Tensor, demands: torch.Tensor) -> torch.Tensor:
    # Normalize demand based on the maximum demand
    max_demand = demands.max().item()
    normalized_demands = demands / max_demand
    
    # Calculate the inverse of the normalized demand
    inverse_normalized_demands = 1 / normalized_demands

    # Calculate the attentional bias
    attentional_bias = distance_matrix * inverse_normalized_demands.unsqueeze(1)

    # Set negative values to -inf
    attentional_bias.masked_fill_(attentional_bias < 0, float('-inf'))

    # Set nan/inf values to 0
    attentional_bias[~torch.isfinite(attentional_bias)] = 0

    return attentional_bias
```
In this improved version of the function, negative values are set to -inf to represent undesirable edges. Additionally, nan and inf values in the attentional bias matrix are set to 0 to ensure proper processing.
