```python
def heuristics_v2(distance_matrix: torch.Tensor, demands: torch.Tensor) -> torch.Tensor:
    n = distance_matrix.size(0)

    # Calculate the maximum possible demand that can be accommodated
    max_demand = 1.0 - demands[0]

    # Normalize demands by dividing by the maximum possible demand
    normalized_demands = demands / max_demand

    # Initialize attentional bias matrix
    attentional_bias = torch.zeros_like(distance_matrix)

    # Calculate the mean distance
    mean_distance = torch.mean(distance_matrix)

    # Calculate the attentional bias matrix using efficient vectorized implementation
    attentional_bias = distance_matrix / mean_distance / normalized_demands.view(-1, 1)

    attentional_bias[torch.isnan(attentional_bias)] = 0
    attentional_bias[torch.isinf(attentional_bias)] = 0

    return attentional_bias
```
In the improved `heuristics_v2` function, I have made the following modifications:
1. I moved the initialization of the attentional bias matrix before the calculations for better performance.
2. I normalized the demands by dividing them by the maximum possible demand.
3. The rest of the code remains the same as in `heuristics_v1`.
